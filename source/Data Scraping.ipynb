{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from symbol import Symbol\n",
    "from index import Index\n",
    "from portifolio import Portifolio\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_variance(returns, weights=None):\n",
    "    if weights is None: \n",
    "        weights = np.ones(returns.columns.size) / \\\n",
    "        returns.columns.size\n",
    "    sigma = np.cov(returns.T,ddof=0)\n",
    "    var = (weights * sigma * weights.T).sum()\n",
    "    return var\n",
    "def sharpe_ratio(returns, weights = None, risk_free_rate = 0.075):\n",
    "    if isinstance(returns, pd.Series):\n",
    "        returns = pd.DataFrame(returns)\n",
    "        return sharpe_ratio(returns, risk_free_rate=risk_free_rate)\n",
    "    n = returns.columns.size\n",
    "    if weights is None: weights = np.ones(n)/n\n",
    "    # get the portfolio variance\n",
    "    var = abs(calculate_variance(returns, weights))\n",
    "    # and the means of the stocks in the portfolio\n",
    "    means = returns.mean()\n",
    "    # and return the sharpe ratio\n",
    "    risk_free_rate = np.log(1+risk_free_rate)/252\n",
    "    sharpe = (means.dot(weights) - risk_free_rate)/np.sqrt(var)\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sym = Symbol()\n",
    "ind = Index()\n",
    "port = Portifolio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=5995, symbol='infy', date=Timestamp('1996-04-30 00:00:00'), action='DIVIDEND', value=3.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=5996, symbol='infy', date=Timestamp('1996-10-28 00:00:00'), action='DIVIDEND', value=1.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=5997, symbol='infy', date=Timestamp('1997-05-23 00:00:00'), action='DIVIDEND', value=4.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=5998, symbol='infy', date=Timestamp('1997-08-19 00:00:00'), action='SPLIT', value=0.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=5999, symbol='infy', date=Timestamp('1997-12-17 00:00:00'), action='DIVIDEND', value=1.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6000, symbol='infy', date=Timestamp('1998-04-30 00:00:00'), action='DIVIDEND', value=4.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6001, symbol='infy', date=Timestamp('1998-11-12 00:00:00'), action='DIVIDEND', value=2.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6002, symbol='infy', date=Timestamp('1999-02-10 00:00:00'), action='SPLIT', value=0.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6003, symbol='infy', date=Timestamp('1999-05-20 00:00:00'), action='DIVIDEND', value=5.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6004, symbol='infy', date=Timestamp('1999-10-28 00:00:00'), action='DIVIDEND', value=3.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6005, symbol='infy', date=Timestamp('2000-01-24 00:00:00'), action='SPLIT', value=0.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6006, symbol='infy', date=Timestamp('2000-04-28 00:00:00'), action='DIVIDEND', value=3.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6007, symbol='infy', date=Timestamp('2000-10-25 00:00:00'), action='DIVIDEND', value=2.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6008, symbol='infy', date=Timestamp('2001-04-27 00:00:00'), action='DIVIDEND', value=7.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6009, symbol='infy', date=Timestamp('2001-10-18 00:00:00'), action='DIVIDEND', value=7.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6010, symbol='infy', date=Timestamp('2002-05-15 00:00:00'), action='DIVIDEND', value=1.8)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6011, symbol='infy', date=Timestamp('2002-05-21 00:00:00'), action='DIVIDEND', value=12.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6012, symbol='infy', date=Timestamp('2002-10-30 00:00:00'), action='DIVIDEND', value=12.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6013, symbol='infy', date=Timestamp('2003-05-28 00:00:00'), action='DIVIDEND', value=14.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6014, symbol='infy', date=Timestamp('2003-10-16 00:00:00'), action='DIVIDEND', value=14.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6015, symbol='infy', date=Timestamp('2003-11-12 00:00:00'), action='DIVIDEND', value=1.2)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6016, symbol='infy', date=Timestamp('2004-05-26 00:00:00'), action='DIVIDEND', value=15.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6017, symbol='infy', date=Timestamp('2004-07-01 00:00:00'), action='SPLIT', value=0.25)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6018, symbol='infy', date=Timestamp('2004-10-18 00:00:00'), action='DIVIDEND', value=5.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6019, symbol='infy', date=Timestamp('2005-06-01 00:00:00'), action='DIVIDEND', value=6.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6020, symbol='infy', date=Timestamp('2005-08-17 00:00:00'), action='DIVIDEND', value=3.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6021, symbol='infy', date=Timestamp('2005-10-17 00:00:00'), action='DIVIDEND', value=6.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6022, symbol='infy', date=Timestamp('2006-05-25 00:00:00'), action='DIVIDEND', value=38.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6023, symbol='infy', date=Timestamp('2006-07-13 00:00:00'), action='SPLIT', value=0.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6024, symbol='infy', date=Timestamp('2006-10-19 00:00:00'), action='DIVIDEND', value=5.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6025, symbol='infy', date=Timestamp('2007-06-06 00:00:00'), action='DIVIDEND', value=6.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6026, symbol='infy', date=Timestamp('2007-10-18 00:00:00'), action='DIVIDEND', value=6.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6027, symbol='infy', date=Timestamp('2008-05-26 00:00:00'), action='DIVIDEND', value=2.2000000000000002)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6028, symbol='infy', date=Timestamp('2008-05-29 00:00:00'), action='DIVIDEND', value=27.25)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6029, symbol='infy', date=Timestamp('2008-10-16 00:00:00'), action='DIVIDEND', value=10.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6030, symbol='infy', date=Timestamp('2009-06-04 00:00:00'), action='DIVIDEND', value=13.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6031, symbol='infy', date=Timestamp('2009-10-15 00:00:00'), action='DIVIDEND', value=10.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6032, symbol='infy', date=Timestamp('2010-05-26 00:00:00'), action='DIVIDEND', value=15.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6033, symbol='infy', date=Timestamp('2010-10-21 00:00:00'), action='DIVIDEND', value=10.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6034, symbol='infy', date=Timestamp('2011-05-26 00:00:00'), action='DIVIDEND', value=20.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6035, symbol='infy', date=Timestamp('2011-10-20 00:00:00'), action='DIVIDEND', value=15.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6036, symbol='infy', date=Timestamp('2012-05-24 00:00:00'), action='DIVIDEND', value=22.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6037, symbol='infy', date=Timestamp('2012-10-18 00:00:00'), action='DIVIDEND', value=15.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6038, symbol='infy', date=Timestamp('2013-05-30 00:00:00'), action='DIVIDEND', value=27.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6039, symbol='infy', date=Timestamp('2013-10-17 00:00:00'), action='DIVIDEND', value=20.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6040, symbol='infy', date=Timestamp('2014-05-29 00:00:00'), action='DIVIDEND', value=43.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6041, symbol='infy', date=Timestamp('2014-10-16 00:00:00'), action='DIVIDEND', value=30.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6042, symbol='infy', date=Timestamp('2014-12-02 00:00:00'), action='SPLIT', value=0.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6043, symbol='infy', date=Timestamp('2015-06-12 00:00:00'), action='DIVIDEND', value=29.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6044, symbol='infy', date=Timestamp('2015-06-15 00:00:00'), action='SPLIT', value=0.5)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6045, symbol='infy', date=Timestamp('2015-10-16 00:00:00'), action='DIVIDEND', value=10.0)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6046, symbol='infy', date=Timestamp('2016-06-09 00:00:00'), action='DIVIDEND', value=14.25)\n",
      "Exception occurred at Cannot add integral value to Timestamp without freq.\n",
      "Pandas(Index=6047, symbol='infy', date=Timestamp('2016-10-21 00:00:00'), action='DIVIDEND', value=11.0)\n"
     ]
    }
   ],
   "source": [
    "infy_data = sym.get_symbol_hist('infy')\n",
    "infy_div = sym.get_dividend_data('infy')\n",
    "index_data = ind.get_index_close(index_list='nifty_50')\n",
    "adj_infy = adjust_closing_prices(infy_data.set_index('date'), infy_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_closing_prices(hist_data, dividend_data):\n",
    "    # Make a copy of hist_data before proceeding\n",
    "    hist_data = hist_data.copy()\n",
    "    hist_data['adj_close'] = hist_data.close\n",
    "    dividend_data = dividend_data.copy()\n",
    "    if type(dividend_data.index[0]) == pd.tslib.Timestamp:\n",
    "        dividend_data = dividend_data.reset_index()\n",
    "\n",
    "    for i in dividend_data.itertuples():\n",
    "        adj_fact = 1\n",
    "        if i.value == 0:\n",
    "                continue\n",
    "        try:\n",
    "            date = hist_data.ix[: i.date].index[-1]\n",
    "            close = hist_data.close.ix[date]\n",
    "        except Exception as e:\n",
    "            print('Exception occurred at during date {0}'.format(e))\n",
    "            print(i)\n",
    "            continue\n",
    "        if i.action == 'DIVIDEND':\n",
    "            adj_fact = (close + i.value) / close\n",
    "        if i.action == 'SPLIT':\n",
    "            adj_fact = 1 / i.value\n",
    "\n",
    "        try:\n",
    "\n",
    "            hist_data.ix[:date, 'adj_close'] = round((hist_data.adj_close[:date] /\n",
    "                                                     adj_fact), 4)\n",
    "            hist_data.ix[date, 'adj_close'] = round((hist_data.adj_close[date] *\n",
    "                                                    adj_fact), 4)\n",
    "        except Exception as e:\n",
    "            print('Exception occurred at {0}'.format(e))\n",
    "            print(i)\n",
    "\n",
    "    return hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_close</th>\n",
       "      <th>nifty_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-01</th>\n",
       "      <td>977.4718</td>\n",
       "      <td>8433.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-02</th>\n",
       "      <td>958.7843</td>\n",
       "      <td>8236.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-03</th>\n",
       "      <td>964.6317</td>\n",
       "      <td>8135.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-04</th>\n",
       "      <td>968.0445</td>\n",
       "      <td>8130.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-05</th>\n",
       "      <td>960.2164</td>\n",
       "      <td>8114.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-08</th>\n",
       "      <td>954.6793</td>\n",
       "      <td>8044.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-09</th>\n",
       "      <td>950.8845</td>\n",
       "      <td>8022.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-10</th>\n",
       "      <td>967.3046</td>\n",
       "      <td>8124.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-11</th>\n",
       "      <td>953.5338</td>\n",
       "      <td>7965.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-12</th>\n",
       "      <td>956.8273</td>\n",
       "      <td>7982.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-15</th>\n",
       "      <td>959.6613</td>\n",
       "      <td>8013.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-16</th>\n",
       "      <td>968.2848</td>\n",
       "      <td>8047.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-17</th>\n",
       "      <td>964.7481</td>\n",
       "      <td>8091.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-18</th>\n",
       "      <td>970.8040</td>\n",
       "      <td>8174.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-19</th>\n",
       "      <td>964.4091</td>\n",
       "      <td>8224.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-22</th>\n",
       "      <td>992.0232</td>\n",
       "      <td>8353.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-23</th>\n",
       "      <td>969.3021</td>\n",
       "      <td>8381.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-24</th>\n",
       "      <td>964.1669</td>\n",
       "      <td>8360.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-25</th>\n",
       "      <td>959.6613</td>\n",
       "      <td>8398.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-26</th>\n",
       "      <td>974.0013</td>\n",
       "      <td>8381.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-29</th>\n",
       "      <td>959.3708</td>\n",
       "      <td>8318.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-30</th>\n",
       "      <td>953.7509</td>\n",
       "      <td>8368.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            adj_close  nifty_50\n",
       "date                           \n",
       "2015-06-01   977.4718   8433.40\n",
       "2015-06-02   958.7843   8236.45\n",
       "2015-06-03   964.6317   8135.10\n",
       "2015-06-04   968.0445   8130.65\n",
       "2015-06-05   960.2164   8114.70\n",
       "2015-06-08   954.6793   8044.15\n",
       "2015-06-09   950.8845   8022.40\n",
       "2015-06-10   967.3046   8124.45\n",
       "2015-06-11   953.5338   7965.35\n",
       "2015-06-12   956.8273   7982.90\n",
       "2015-06-15   959.6613   8013.90\n",
       "2015-06-16   968.2848   8047.30\n",
       "2015-06-17   964.7481   8091.55\n",
       "2015-06-18   970.8040   8174.60\n",
       "2015-06-19   964.4091   8224.95\n",
       "2015-06-22   992.0232   8353.10\n",
       "2015-06-23   969.3021   8381.55\n",
       "2015-06-24   964.1669   8360.85\n",
       "2015-06-25   959.6613   8398.00\n",
       "2015-06-26   974.0013   8381.10\n",
       "2015-06-29   959.3708   8318.40\n",
       "2015-06-30   953.7509   8368.50"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_infy = adjust_closing_prices(infy_data.set_index('date'), infy_div)\n",
    "infy_adata = pd.DataFrame(adj_infy.adj_close).join(index_data).dropna()\n",
    "# infy_data.to_csv('Daily_Close.csv')\n",
    "# infy_data.resample('W-FRI').last().to_csv('Weekly_Close.csv')\n",
    "# infy_data.resample('M').last().to_csv('Monthly_Close.csv')\n",
    "# infy_data.resample('Q-MAR').last().to_csv('Quarterly_Close.csv')\n",
    "# infy_data.resample('A').last().to_csv('Annual_Close.csv')\n",
    "infy_adata['2015-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "port = s.Portifolio(index='nifty_500', start=2010, null_count=5, volume=1000, benchmark='nifty_50')\n",
    "len(port.symbol_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdata = port.get_symbol_hist()\n",
    "hret = port.get_symbol_returns().interpolate(limit=5)\n",
    "iret = port.get_index_returns()\n",
    "hret = hret.dropna(axis=1)\n",
    "scaled_hret = pd.DataFrame(scale(hret), columns=hret.columns.copy(), index=hret.index.copy())\n",
    "hclose = port.get_symbol_close()\n",
    "pref_symbols = hclose.columns[hclose.ix[-1, :] <= 1000]\n",
    "pref_symbols = pref_symbols.intersection(hret.columns)\n",
    "hret = hret[pref_symbols]\n",
    "hclose = hclose[pref_symbols]\n",
    "len(hret), len(hret.columns), len(iret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bench_port = port.create_portifolio(ret=hret['2010':'2015'])\n",
    "new_port = port.create_portifolio(ret=hret['2016'])\n",
    "sharpe_ratio(bench_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.optimize as scopt\n",
    "import scipy.stats as spstats\n",
    "def negative_sharpe_ratio_n_minus_1_stock(weights, \n",
    "                                          returns, \n",
    "                                          risk_free_rate):\n",
    "    \"\"\"\n",
    "    Given n-1 weights, return a negative sharpe ratio\n",
    "    \"\"\"\n",
    "    weights = weights.round()\n",
    "    return -sharpe_ratio(returns, weights, risk_free_rate)\n",
    "def optimize_portfolio(returns, risk_free_rate):\n",
    "    \"\"\" \n",
    "    Performs the optimization\n",
    "    \"\"\"\n",
    "    # start with equal weights\n",
    "    w0 = [100/returns.columns.size for i in range(returns.columns.size)]\n",
    "    cons = ({'type': 'eq', 'fun': lambda x:  x.sum()-100},\n",
    "           {'type':'eq', 'fun': lambda x: (x<0).sum()})\n",
    "    # minimize the negative sharpe value\n",
    "    w1 = scopt.minimize(negative_sharpe_ratio_n_minus_1_stock, \n",
    "                        w0, args=(returns, risk_free_rate),method='COBYLA',\n",
    "                        options={'disp': True})\n",
    "    # build final set of weights\n",
    "    final_w = (w1.x).round()\n",
    "    # and calculate the final, optimized, sharpe ratio\n",
    "    final_sharpe = sharpe_ratio(returns, final_w, risk_free_rate)\n",
    "    return (final_w.round(), final_sharpe)\n",
    "optimize_portfolio(bench_port.ix[:, 0:10], 0.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharpe_ratio(bench_port.ix[:, 0:6])\n",
    "sh_w = []\n",
    "def helsf(returns, hclose):\n",
    "    max_sh = -np.inf\n",
    "    i = 0\n",
    "    n = returns.columns.size\n",
    "    hclose = hclose[returns.columns].copy()\n",
    "#     weights = [0 for p in range(n)]\n",
    "    while i < 1000:\n",
    "        weights =(constrained_sum_sample_pos(n, 100 + n))\n",
    "        if hclose.dot(weights).ix[-1] > 10000:\n",
    "            i = i+0.5\n",
    "            continue\n",
    "        if weights not in sh_w:\n",
    "            sh_w.append((weights))\n",
    "        else:\n",
    "            i = i+0.5\n",
    "            continue\n",
    "        weights = np.array(weights)\n",
    "        sharpe_rat = sharpe_ratio(returns, weights)\n",
    "        if sharpe_rat > max_sh:\n",
    "            max_i = i\n",
    "            max_sh = sharpe_rat\n",
    "            max_weights = weights\n",
    "        i = i+1\n",
    "    return max_i, max_sh, max_weights\n",
    "helsf(hret.ix[:, 0:10], hclose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(8879.0, 8.6029805156065411, array([9, 3, 9, 2, 5, 2]))\n",
    "(5766, 253.56645536686179, array([14,  0,  0,  3,  1,  4,  3,  3,  1,  1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[ 24.0438623 ,  12.02346529,  18.95166979,   5.76427132,\n",
    "          7.8546917 ,   9.34415854,   0.37967011,  11.13532162,\n",
    "          8.3874864 ,   6.33986876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def constrained_sum_sample_pos(n, total):\n",
    "    \"\"\"Return a randomly chosen list of n positive integers summing to total.\n",
    "    Each such list is equally likely to occur.\"\"\"\n",
    "\n",
    "    dividers = sorted(random.sample(range(1, total), n - 1))\n",
    "    return [a - b - 1 for a, b in zip(dividers + [total], [0] + dividers)]\n",
    "constrained_sum_sample_pos(10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prob(ret):\n",
    "    vals = pd.cut(ret*100, bins=[-20, -10, -5, -2,-0.5, 0.5, 2, 5, 10, 20], labels=[-4, -3, -2, -1, 0, 1, 2, 3, 4]).value_counts()\n",
    "    prob = (vals/vals.sum()).sort_index()\n",
    "    return prob\n",
    "prob_ret = hret.dropna(how='all', axis=1).apply(prob)\n",
    "prob_ret.index = prob_ret.index.as_ordered()\n",
    "prob_ret=prob_ret.T\n",
    "prob_cond =(prob_ret.loc[:, [-4,-3]] == 0)\n",
    "prob_ret[prob_cond.sum(axis=1) == len(prob_cond.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sharpe = hret['2010':'2015'].apply(sharpe_ratio)\n",
    "beta = port.calculate_capm(returns=hret['2010':'2015'], benchmark_returns=iret['2010':'2015']).reset_index(drop=True).set_index('symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_returns = pd.DataFrame(hret.sum(), columns=['tot_returns'])\n",
    "avg_returns = pd.DataFrame(hret.mean(), columns=['avg_returns'])\n",
    "std_dev = pd.DataFrame(hret.std(), columns=['std_dev'])\n",
    "returns = total_returns.join(avg_returns).join(std_dev)\n",
    "returns = returns.join(pd.DataFrame(sharpe, columns=['sharpe'])).join(beta.beta)\n",
    "returns.sort_values('tot_returns', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "returns.plot(kind='scatter',x='sharpe', y='beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharpe = sharpe.sort_values(ascending=False)\n",
    "symbol_list = sharpe.index[0:20]\n",
    "print(symbol_list)\n",
    "new_sharpe = hret['2016':].apply(sharpe_ratio).sort_values(ascending=False)\n",
    "hret['2016'][symbol_list].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sym_list = returns.sort_values('sharpe', ascending=False).head(30).index.tolist()\n",
    "opt_port = s.Portifolio(start=2016,index='nifty_50', benchmark='nifty_50')\n",
    "hdata = opt_port.get_symbol_hist()\n",
    "hret = opt_port.get_symbol_returns()\n",
    "iret = opt_port.get_index_returns()\n",
    "hret = hret.dropna(axis=1)\n",
    "scaled_hret = pd.DataFrame(scale(hret), columns=hret.columns.copy(), index=hret.index.copy())\n",
    "sharpe = hret.apply(sharpe_ratio)\n",
    "beta = port.calculate_capm(returns=hret, benchmark_returns=iret).reset_index(drop=True).set_index('symbol')\n",
    "total_returns = pd.DataFrame(hret.sum(), columns=['tot_returns'])\n",
    "avg_returns = pd.DataFrame(hret.mean(), columns=['avg_returns'])\n",
    "std_dev = pd.DataFrame(hret.std(), columns=['std_dev'])\n",
    "opt_returns = total_returns.join(avg_returns).join(std_dev)\n",
    "opt_returns = opt_returns.join(pd.DataFrame(sharpe, columns=['sharpe'])).join(beta.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# opt_returns.plot(kind='scatter',x='tot_returns', y='std_dev')\n",
    "ps = sns.regplot(data=opt_returns, x='std_dev', y='sharpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infy_ret = ret.infy.copy()\n",
    "mean = infy_ret.mean()\n",
    "std = infy_ret.std()\n",
    "new = pd.Series(np.random.normal(loc=mean, scale=std, size=len(infy_ret)), index=infy_ret.index.copy())\n",
    "new[abs(new) > mean+2*std] = 0\n",
    "infy = pd.DataFrame(index=infy_ret.index.copy())\n",
    "infy['original'] = 1000\n",
    "infy['original'] = infy.original * np.exp(infy_ret.cumsum())\n",
    "infy['random'] = 1000\n",
    "infy['random'] = infy.random * np.exp(new.cumsum())\n",
    "print(infy.mean())\n",
    "infy.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "infy_ret = ret.infy['2007'].copy()\n",
    "mean = infy_ret.mean()\n",
    "std = infy_ret.std()\n",
    "infy_ret = ret.infy['2007'].copy()\n",
    "monte = pd.DataFrame(index=infy_ret.index.copy())\n",
    "for i in range(0, 100):\n",
    "    new = pd.Series(np.random.normal(loc=mean, scale=std, size=len(infy_ret)), index=infy_ret.index.copy(), name=str(i))\n",
    "    monte[str(i)] = 1000\n",
    "    monte[str(i)] = monte[str(i)] * np.exp(new.cumsum())\n",
    "monte['2007-01':'2007-01-10'].plot(legend=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(ret['2016'].corr(), vmax=.8, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='infy', y='wipro', data=ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gammas = sns.load_dataset(\"gammas\")\n",
    "\n",
    "# # Plot the response with standard error\n",
    "# sns.tsplot(data=gammas, time=\"timepoint\", unit=\"subject\",\n",
    "#            condition=\"ROI\", value=\"BOLD signal\")\n",
    "# prob_pivot = pd.pivot(prob_ret, index=)\n",
    "gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smeta[(smeta.tech_strength >= 7) & (smeta.mcap > np.mean(smeta.mcap))].sort_values('tech_strength', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sps = pd.read_html('http://techpaisa.com/stock/20microns')\n",
    "sps[0]\n",
    "sps[3]\n",
    "sps[7]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

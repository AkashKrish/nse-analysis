{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import symbol as s\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_variance(returns, weights=None):\n",
    "    if weights is None: \n",
    "        weights = np.ones(returns.columns.size) / \\\n",
    "        returns.columns.size\n",
    "    sigma = np.cov(returns.T,ddof=0)\n",
    "    var = (weights * sigma * weights.T).sum()\n",
    "    return var\n",
    "def sharpe_ratio(returns, weights = None, risk_free_rate = 0.075):\n",
    "    if isinstance(returns, pd.Series):\n",
    "        returns = pd.DataFrame(returns)\n",
    "        return sharpe_ratio(returns, risk_free_rate=risk_free_rate)\n",
    "    n = returns.columns.size\n",
    "    if weights is None: weights = np.ones(n)/n\n",
    "    # get the portfolio variance\n",
    "    var = abs(calculate_variance(returns, weights))\n",
    "    # and the means of the stocks in the portfolio\n",
    "    means = returns.mean()\n",
    "    # and return the sharpe ratio\n",
    "    risk_free_rate = np.log(1+risk_free_rate)/252\n",
    "    sharpe = (means.dot(weights) - risk_free_rate)/np.sqrt(var)\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sym = s.Symbol()\n",
    "ind = s.Index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infy_data = sym.get_symbol_hist('bhel')\n",
    "infy_div = sym.get_dividend_data('bhel')\n",
    "index_data = ind.get_index_hist(index_list='nifty_50')\n",
    "adj_infy = adjust_closing_prices(infy_data.set_index('date'), infy_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_closing_prices(hist_data, dividend_data):\n",
    "    # Make a copy of hist_data before proceeding\n",
    "    hist_data = hist_data.copy()\n",
    "    hist_data['adj_close'] = hist_data.close\n",
    "    dividend_data = dividend_data.copy()\n",
    "    if type(dividend_data.index[0]) == pd.tslib.Timestamp:\n",
    "        dividend_data = dividend_data.reset_index()\n",
    "\n",
    "    for i in dividend_data.itertuples():\n",
    "        adj_fact = 1\n",
    "        if i.value == 0:\n",
    "                continue\n",
    "        try:\n",
    "            date = hist_data.ix[: i.date].index[-1]\n",
    "            close = hist_data.close.ix[date]\n",
    "        except Exception as e:\n",
    "            print('Exception occurred at during date {0}'.format(e))\n",
    "            print(i)\n",
    "            continue\n",
    "        if i.action == 'DIVIDEND':\n",
    "            adj_fact = (close + i.value) / close\n",
    "        if i.action == 'SPLIT':\n",
    "            adj_fact = 1 / i.value\n",
    "\n",
    "        try:\n",
    "\n",
    "            hist_data.ix[:date, 'adj_close'] = round((hist_data.adj_close[:date] /\n",
    "                                                     adj_fact), 4)\n",
    "            hist_data.ix[date, 'adj_close'] = round((hist_data.adj_close[date] *\n",
    "                                                    adj_fact), 4)\n",
    "        except Exception as e:\n",
    "            print('Exception occurred at {0}'.format(e))\n",
    "            print(i)\n",
    "\n",
    "    return hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infy_data = pd.DataFrame(adj_infy['2006':].adj_close).join(index_data).dropna()\n",
    "infy_data.to_csv('Daily_Close.csv')\n",
    "infy_data.resample('W-FRI').last().to_csv('Weekly_Close.csv')\n",
    "infy_data.resample('M').last().to_csv('Monthly_Close.csv')\n",
    "infy_data.resample('Q-MAR').last().to_csv('Quarterly_Close.csv')\n",
    "infy_data.resample('A').last().to_csv('Annual_Close.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "port = s.Portifolio(index='nifty_500', start=2010, null_count=5, volume=1000, benchmark='nifty_50')\n",
    "len(port.symbol_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdata = port.get_symbol_hist()\n",
    "hret = port.get_symbol_returns().interpolate(limit=5)\n",
    "iret = port.get_index_returns()\n",
    "hret = hret.dropna(axis=1)\n",
    "scaled_hret = pd.DataFrame(scale(hret), columns=hret.columns.copy(), index=hret.index.copy())\n",
    "hclose = port.get_symbol_close()\n",
    "pref_symbols = hclose.columns[hclose.ix[-1, :] <= 1000]\n",
    "pref_symbols = pref_symbols.intersection(hret.columns)\n",
    "hret = hret[pref_symbols]\n",
    "hclose = hclose[pref_symbols]\n",
    "len(hret), len(hret.columns), len(iret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bench_port = port.create_portifolio(ret=hret['2010':'2015'])\n",
    "new_port = port.create_portifolio(ret=hret['2016'])\n",
    "sharpe_ratio(bench_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.optimize as scopt\n",
    "import scipy.stats as spstats\n",
    "def negative_sharpe_ratio_n_minus_1_stock(weights, \n",
    "                                          returns, \n",
    "                                          risk_free_rate):\n",
    "    \"\"\"\n",
    "    Given n-1 weights, return a negative sharpe ratio\n",
    "    \"\"\"\n",
    "    weights = weights.round()\n",
    "    return -sharpe_ratio(returns, weights, risk_free_rate)\n",
    "def optimize_portfolio(returns, risk_free_rate):\n",
    "    \"\"\" \n",
    "    Performs the optimization\n",
    "    \"\"\"\n",
    "    # start with equal weights\n",
    "    w0 = [100/returns.columns.size for i in range(returns.columns.size)]\n",
    "    cons = ({'type': 'eq', 'fun': lambda x:  x.sum()-100},\n",
    "           {'type':'eq', 'fun': lambda x: (x<0).sum()})\n",
    "    # minimize the negative sharpe value\n",
    "    w1 = scopt.minimize(negative_sharpe_ratio_n_minus_1_stock, \n",
    "                        w0, args=(returns, risk_free_rate),method='COBYLA',\n",
    "                        options={'disp': True})\n",
    "    # build final set of weights\n",
    "    final_w = (w1.x).round()\n",
    "    # and calculate the final, optimized, sharpe ratio\n",
    "    final_sharpe = sharpe_ratio(returns, final_w, risk_free_rate)\n",
    "    return (final_w.round(), final_sharpe)\n",
    "optimize_portfolio(bench_port.ix[:, 0:10], 0.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharpe_ratio(bench_port.ix[:, 0:6])\n",
    "sh_w = []\n",
    "def helsf(returns, hclose):\n",
    "    max_sh = -np.inf\n",
    "    i = 0\n",
    "    n = returns.columns.size\n",
    "    hclose = hclose[returns.columns].copy()\n",
    "#     weights = [0 for p in range(n)]\n",
    "    while i < 1000:\n",
    "        weights =(constrained_sum_sample_pos(n, 100 + n))\n",
    "        if hclose.dot(weights).ix[-1] > 10000:\n",
    "            i = i+0.5\n",
    "            continue\n",
    "        if weights not in sh_w:\n",
    "            sh_w.append((weights))\n",
    "        else:\n",
    "            i = i+0.5\n",
    "            continue\n",
    "        weights = np.array(weights)\n",
    "        sharpe_rat = sharpe_ratio(returns, weights)\n",
    "        if sharpe_rat > max_sh:\n",
    "            max_i = i\n",
    "            max_sh = sharpe_rat\n",
    "            max_weights = weights\n",
    "        i = i+1\n",
    "    return max_i, max_sh, max_weights\n",
    "helsf(hret.ix[:, 0:10], hclose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(8879.0, 8.6029805156065411, array([9, 3, 9, 2, 5, 2]))\n",
    "(5766, 253.56645536686179, array([14,  0,  0,  3,  1,  4,  3,  3,  1,  1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[ 24.0438623 ,  12.02346529,  18.95166979,   5.76427132,\n",
    "          7.8546917 ,   9.34415854,   0.37967011,  11.13532162,\n",
    "          8.3874864 ,   6.33986876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def constrained_sum_sample_pos(n, total):\n",
    "    \"\"\"Return a randomly chosen list of n positive integers summing to total.\n",
    "    Each such list is equally likely to occur.\"\"\"\n",
    "\n",
    "    dividers = sorted(random.sample(range(1, total), n - 1))\n",
    "    return [a - b - 1 for a, b in zip(dividers + [total], [0] + dividers)]\n",
    "constrained_sum_sample_pos(10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prob(ret):\n",
    "    vals = pd.cut(ret*100, bins=[-20, -10, -5, -2,-0.5, 0.5, 2, 5, 10, 20], labels=[-4, -3, -2, -1, 0, 1, 2, 3, 4]).value_counts()\n",
    "    prob = (vals/vals.sum()).sort_index()\n",
    "    return prob\n",
    "prob_ret = hret.dropna(how='all', axis=1).apply(prob)\n",
    "prob_ret.index = prob_ret.index.as_ordered()\n",
    "prob_ret=prob_ret.T\n",
    "prob_cond =(prob_ret.loc[:, [-4,-3]] == 0)\n",
    "prob_ret[prob_cond.sum(axis=1) == len(prob_cond.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sharpe = hret['2010':'2015'].apply(sharpe_ratio)\n",
    "beta = port.calculate_capm(returns=hret['2010':'2015'], benchmark_returns=iret['2010':'2015']).reset_index(drop=True).set_index('symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_returns = pd.DataFrame(hret.sum(), columns=['tot_returns'])\n",
    "avg_returns = pd.DataFrame(hret.mean(), columns=['avg_returns'])\n",
    "std_dev = pd.DataFrame(hret.std(), columns=['std_dev'])\n",
    "returns = total_returns.join(avg_returns).join(std_dev)\n",
    "returns = returns.join(pd.DataFrame(sharpe, columns=['sharpe'])).join(beta.beta)\n",
    "returns.sort_values('tot_returns', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "returns.plot(kind='scatter',x='sharpe', y='beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharpe = sharpe.sort_values(ascending=False)\n",
    "symbol_list = sharpe.index[0:20]\n",
    "print(symbol_list)\n",
    "new_sharpe = hret['2016':].apply(sharpe_ratio).sort_values(ascending=False)\n",
    "hret['2016'][symbol_list].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sym_list = returns.sort_values('sharpe', ascending=False).head(30).index.tolist()\n",
    "opt_port = s.Portifolio(start=2016,index='nifty_50', benchmark='nifty_50')\n",
    "hdata = opt_port.get_symbol_hist()\n",
    "hret = opt_port.get_symbol_returns()\n",
    "iret = opt_port.get_index_returns()\n",
    "hret = hret.dropna(axis=1)\n",
    "scaled_hret = pd.DataFrame(scale(hret), columns=hret.columns.copy(), index=hret.index.copy())\n",
    "sharpe = hret.apply(sharpe_ratio)\n",
    "beta = port.calculate_capm(returns=hret, benchmark_returns=iret).reset_index(drop=True).set_index('symbol')\n",
    "total_returns = pd.DataFrame(hret.sum(), columns=['tot_returns'])\n",
    "avg_returns = pd.DataFrame(hret.mean(), columns=['avg_returns'])\n",
    "std_dev = pd.DataFrame(hret.std(), columns=['std_dev'])\n",
    "opt_returns = total_returns.join(avg_returns).join(std_dev)\n",
    "opt_returns = opt_returns.join(pd.DataFrame(sharpe, columns=['sharpe'])).join(beta.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# opt_returns.plot(kind='scatter',x='tot_returns', y='std_dev')\n",
    "ps = sns.regplot(data=opt_returns, x='std_dev', y='sharpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infy_ret = ret.infy.copy()\n",
    "mean = infy_ret.mean()\n",
    "std = infy_ret.std()\n",
    "new = pd.Series(np.random.normal(loc=mean, scale=std, size=len(infy_ret)), index=infy_ret.index.copy())\n",
    "new[abs(new) > mean+2*std] = 0\n",
    "infy = pd.DataFrame(index=infy_ret.index.copy())\n",
    "infy['original'] = 1000\n",
    "infy['original'] = infy.original * np.exp(infy_ret.cumsum())\n",
    "infy['random'] = 1000\n",
    "infy['random'] = infy.random * np.exp(new.cumsum())\n",
    "print(infy.mean())\n",
    "infy.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "infy_ret = ret.infy['2007'].copy()\n",
    "mean = infy_ret.mean()\n",
    "std = infy_ret.std()\n",
    "infy_ret = ret.infy['2007'].copy()\n",
    "monte = pd.DataFrame(index=infy_ret.index.copy())\n",
    "for i in range(0, 100):\n",
    "    new = pd.Series(np.random.normal(loc=mean, scale=std, size=len(infy_ret)), index=infy_ret.index.copy(), name=str(i))\n",
    "    monte[str(i)] = 1000\n",
    "    monte[str(i)] = monte[str(i)] * np.exp(new.cumsum())\n",
    "monte['2007-01':'2007-01-10'].plot(legend=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(ret['2016'].corr(), vmax=.8, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='infy', y='wipro', data=ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gammas = sns.load_dataset(\"gammas\")\n",
    "\n",
    "# # Plot the response with standard error\n",
    "# sns.tsplot(data=gammas, time=\"timepoint\", unit=\"subject\",\n",
    "#            condition=\"ROI\", value=\"BOLD signal\")\n",
    "# prob_pivot = pd.pivot(prob_ret, index=)\n",
    "gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smeta[(smeta.tech_strength >= 7) & (smeta.mcap > np.mean(smeta.mcap))].sort_values('tech_strength', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sps = pd.read_html('http://techpaisa.com/stock/20microns')\n",
    "sps[0]\n",
    "sps[3]\n",
    "sps[7]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
